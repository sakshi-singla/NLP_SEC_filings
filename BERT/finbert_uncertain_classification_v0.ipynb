{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finbert_uncertain_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRnNV1pbimz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c1f3e4a-0ae9-46d0-cba5-929bbd9f7456"
      },
      "source": [
        "! pip install finbert-embedding==0.1.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting finbert-embedding==0.1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/65/74/62c14e0960b5815da757e4e28d06166ddd879b4931d5a900ea97e3d9cb58/finbert_embedding-0.1.4-py3-none-any.whl\n",
            "Collecting torch==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9MB)\n",
            "\u001b[K     |████████████████████████████████| 676.9MB 25kB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert==0.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from finbert-embedding==0.1.4) (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0->finbert-embedding==0.1.4) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.14.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2.23.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.34.2)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.29.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.9.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (1.4.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->finbert-embedding==0.1.4) (3.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.5 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.17.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (1.24.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (47.3.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (1.6.0.post3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.5->boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.5->boto3->pytorch-pretrained-bert==0.6.2->finbert-embedding==0.1.4) (0.15.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (1.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (4.1.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->finbert-embedding==0.1.4) (3.1.0)\n",
            "\u001b[31mERROR: torchvision 0.6.1+cu101 has requirement torch==1.5.1, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, pytorch-pretrained-bert, finbert-embedding\n",
            "  Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "Successfully installed finbert-embedding-0.1.4 pytorch-pretrained-bert-0.6.2 torch-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC4Gl6TvmZ4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOvEJcn7yHyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9RXB7u4mEiw",
        "colab_type": "text"
      },
      "source": [
        "# Play around with Finbert library\n",
        "https://pypi.org/project/finbert-embedding/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_0FFpC586wR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = Path(\"/content/\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jop5cLwtipNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from finbert_embedding.embedding import FinbertEmbedding"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfCTSZzkj9kl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e74143b9-3dfb-49fe-f6c5-2542bd26863f"
      },
      "source": [
        "finbert = FinbertEmbedding()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.dropbox.com/s/6oeprcqae7tc459/fin_model.tar.gz?dl=1\n",
            "407994368/407986644 [==============================] - 32s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICx55e47ktot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"classification.csv\",header=None, names=['sentence', 'label'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8opBzxzKmYQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eb159d20-40fa-4b48-fa97-62e91fd4a756"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For example, we may record as regulatory asset...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In connection with this transaction, all of ou...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The warrants were valued using the Black-Schol...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In July of 2006, we entered into an operating ...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Certain regulatory assets do not result from c...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence label\n",
              "0  For example, we may record as regulatory asset...     c\n",
              "1  In connection with this transaction, all of ou...     c\n",
              "2  The warrants were valued using the Black-Schol...     c\n",
              "3  In July of 2006, we entered into an operating ...     c\n",
              "4  Certain regulatory assets do not result from c...     c"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMwlAkQzmekS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {v: i for i,v in enumerate(df.label.unique())}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ1e-kEVnA_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08344d9d-b972-4c6e-8b5c-78d457a2c82b"
      },
      "source": [
        "d"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c': 0, 'u': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhvNLMC5nfSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "labels_idx = [d[label] for label in labels]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5WgL0v-nnoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embeddings_list = []\n",
        "sentence_embeddings_list = []\n",
        "for sentence in sentences:\n",
        "    word_embeddings = finbert.word_vector(text = sentence)\n",
        "    word_embeddings = np.vstack([emb.numpy() for emb in word_embeddings])\n",
        "    word_embeddings_list.append(word_embeddings)\n",
        "    sentence_embedding = finbert.sentence_vector(text = sentence)\n",
        "    sentence_embedding = sentence_embedding.numpy()\n",
        "    sentence_embeddings_list.append(sentence_embedding)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OSoPSCb-DqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "identifier = np.random.random(1000)\n",
        "identifier[np.where(identifier<0.8)] = 0\n",
        "identifier[np.where((identifier >=0.8) & (identifier <0.9))] = 1\n",
        "identifier[np.where((identifier >=0.9)& (identifier <1.0))] = 2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6aFsLYMtQWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['train/test/valid'] = identifier"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCr256hltcKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"sent_emb\"] = word_embeddings_list\n",
        "df[\"sent_avg_emb\"] = sentence_embeddings_list\n",
        "df[\"label\"] = labels_idx"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UbgoZm9tm_B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "b118a842-c7dc-4cf4-9993-fbe05d3c8ae3"
      },
      "source": [
        "df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>train/test/valid</th>\n",
              "      <th>sent_emb</th>\n",
              "      <th>sent_avg_emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For example, we may record as regulatory asset...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[[-3.0068293, 2.1747842, 0.08535655, -1.333302...</td>\n",
              "      <td>[-0.07628794, 0.07385665, 0.22439034, 0.113049...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In connection with this transaction, all of ou...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-7.2349834, 0.7282898, 0.44459042, -3.69149,...</td>\n",
              "      <td>[-0.2181889, 0.25167054, 0.21129918, 0.0914831...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The warrants were valued using the Black-Schol...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-4.7428164, -2.0988667, 0.5116024, -0.578443...</td>\n",
              "      <td>[-0.28901023, 0.14081945, 0.17879683, 0.128653...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In July of 2006, we entered into an operating ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[-9.793489, -0.65220696, 0.13868378, 1.696403...</td>\n",
              "      <td>[-0.26589411, 0.29738006, 0.2962963, -0.096300...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Certain regulatory assets do not result from c...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-3.8283665, 4.249455, -0.1129528, -0.4282031...</td>\n",
              "      <td>[-0.24734896, 0.32598937, 0.28862736, 0.164214...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The 2000 volumes reflect the impact of additio...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[-7.4123354, 0.45839158, -0.9591343, -0.77836...</td>\n",
              "      <td>[-0.65662414, 0.1849709, 0.38781762, -0.004934...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The exercise price per share for each such opt...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-1.9446385, -1.0628954, -0.9985801, -1.54941...</td>\n",
              "      <td>[-0.33660322, 0.20990066, 0.1513533, 0.1885641...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>As of June 30, 2006, the outstanding mortgage ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-10.131733, -0.16516311, 1.8880061, -1.89035...</td>\n",
              "      <td>[-0.6541173, 0.2995038, 0.25971296, -0.0529209...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The General Partner and the Commodity Broker p...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-5.572422, 2.187811, -0.925772, -1.2603581, ...</td>\n",
              "      <td>[-0.2163732, 0.26890123, 0.09922831, -0.040265...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Clients pay for inclusion of their interviews ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[1.8370683, 0.5006188, 1.0635892, 0.4025683, ...</td>\n",
              "      <td>[-0.14310639, 0.21774745, 0.077866174, 0.10760...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentence  ...                                       sent_avg_emb\n",
              "0    For example, we may record as regulatory asset...  ...  [-0.07628794, 0.07385665, 0.22439034, 0.113049...\n",
              "1    In connection with this transaction, all of ou...  ...  [-0.2181889, 0.25167054, 0.21129918, 0.0914831...\n",
              "2    The warrants were valued using the Black-Schol...  ...  [-0.28901023, 0.14081945, 0.17879683, 0.128653...\n",
              "3    In July of 2006, we entered into an operating ...  ...  [-0.26589411, 0.29738006, 0.2962963, -0.096300...\n",
              "4    Certain regulatory assets do not result from c...  ...  [-0.24734896, 0.32598937, 0.28862736, 0.164214...\n",
              "..                                                 ...  ...                                                ...\n",
              "995  The 2000 volumes reflect the impact of additio...  ...  [-0.65662414, 0.1849709, 0.38781762, -0.004934...\n",
              "996  The exercise price per share for each such opt...  ...  [-0.33660322, 0.20990066, 0.1513533, 0.1885641...\n",
              "997  As of June 30, 2006, the outstanding mortgage ...  ...  [-0.6541173, 0.2995038, 0.25971296, -0.0529209...\n",
              "998  The General Partner and the Commodity Broker p...  ...  [-0.2163732, 0.26890123, 0.09922831, -0.040265...\n",
              "999  Clients pay for inclusion of their interviews ...  ...  [-0.14310639, 0.21774745, 0.077866174, 0.10760...\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmMTjRg6u73I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f6b3c19-74cd-41c2-c5e8-8c32ca588b16"
      },
      "source": [
        "max = 0\n",
        "min = float(\"inf\")\n",
        "for i in word_embeddings_list:\n",
        "    if i.shape[0] > max:\n",
        "        max = i.shape[0]\n",
        "    if i.shape[0] < min:\n",
        "        min = i.shape[0]\n",
        "print(max)\n",
        "print(min)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3sVeGN8v2py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add padding to sent_emb\n",
        "padded_embeddings_list = []\n",
        "for emb in word_embeddings_list:\n",
        "    if emb.shape[0] != max:\n",
        "        tmp = np.vstack((emb,np.zeros((max-emb.shape[0],768))))\n",
        "        padded_embeddings_list.append(tmp)\n",
        "    else:\n",
        "        padded_embeddings_list.append(emb)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_By0PX8xT1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf1c6f0a-95aa-48ed-e9df-7f1b5253eb0b"
      },
      "source": [
        "# Check\n",
        "padded_embeddings_list[7].shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(172, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2WdV4_GxnRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"padded_sent\"] = padded_embeddings_list"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk5t-uZZtnul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ce00ee12-ebaa-4bab-abcc-c8fe248dd34d"
      },
      "source": [
        "df[df[\"label\"] == 1].count()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence            130\n",
              "label               130\n",
              "train/test/valid    130\n",
              "sent_emb            130\n",
              "sent_avg_emb        130\n",
              "padded_sent         130\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7ZzROImyXqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "a29d9cf4-bfc9-455e-90f5-3cedb78068ab"
      },
      "source": [
        "df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>train/test/valid</th>\n",
              "      <th>sent_emb</th>\n",
              "      <th>sent_avg_emb</th>\n",
              "      <th>padded_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For example, we may record as regulatory asset...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[[-3.0068293, 2.1747842, 0.08535655, -1.333302...</td>\n",
              "      <td>[-0.07628794, 0.07385665, 0.22439034, 0.113049...</td>\n",
              "      <td>[[-3.006829261779785, 2.1747841835021973, 0.08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In connection with this transaction, all of ou...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-7.2349834, 0.7282898, 0.44459042, -3.69149,...</td>\n",
              "      <td>[-0.2181889, 0.25167054, 0.21129918, 0.0914831...</td>\n",
              "      <td>[[-7.234983444213867, 0.728289783000946, 0.444...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The warrants were valued using the Black-Schol...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-4.7428164, -2.0988667, 0.5116024, -0.578443...</td>\n",
              "      <td>[-0.28901023, 0.14081945, 0.17879683, 0.128653...</td>\n",
              "      <td>[[-4.74281644821167, -2.0988667011260986, 0.51...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In July of 2006, we entered into an operating ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[-9.793489, -0.65220696, 0.13868378, 1.696403...</td>\n",
              "      <td>[-0.26589411, 0.29738006, 0.2962963, -0.096300...</td>\n",
              "      <td>[[-9.793489456176758, -0.6522069573402405, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Certain regulatory assets do not result from c...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-3.8283665, 4.249455, -0.1129528, -0.4282031...</td>\n",
              "      <td>[-0.24734896, 0.32598937, 0.28862736, 0.164214...</td>\n",
              "      <td>[[-3.82836651802063, 4.249454975128174, -0.112...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>The 2000 volumes reflect the impact of additio...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[-7.4123354, 0.45839158, -0.9591343, -0.77836...</td>\n",
              "      <td>[-0.65662414, 0.1849709, 0.38781762, -0.004934...</td>\n",
              "      <td>[[-7.412335395812988, 0.45839157700538635, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The exercise price per share for each such opt...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-1.9446385, -1.0628954, -0.9985801, -1.54941...</td>\n",
              "      <td>[-0.33660322, 0.20990066, 0.1513533, 0.1885641...</td>\n",
              "      <td>[[-1.9446384906768799, -1.06289541721344, -0.9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>As of June 30, 2006, the outstanding mortgage ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-10.131733, -0.16516311, 1.8880061, -1.89035...</td>\n",
              "      <td>[-0.6541173, 0.2995038, 0.25971296, -0.0529209...</td>\n",
              "      <td>[[-10.131732940673828, -0.16516311466693878, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The General Partner and the Commodity Broker p...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[-5.572422, 2.187811, -0.925772, -1.2603581, ...</td>\n",
              "      <td>[-0.2163732, 0.26890123, 0.09922831, -0.040265...</td>\n",
              "      <td>[[-5.572422027587891, 2.1878108978271484, -0.9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Clients pay for inclusion of their interviews ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[[1.8370683, 0.5006188, 1.0635892, 0.4025683, ...</td>\n",
              "      <td>[-0.14310639, 0.21774745, 0.077866174, 0.10760...</td>\n",
              "      <td>[[1.8370683193206787, 0.5006188154220581, 1.06...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentence  ...                                        padded_sent\n",
              "0    For example, we may record as regulatory asset...  ...  [[-3.006829261779785, 2.1747841835021973, 0.08...\n",
              "1    In connection with this transaction, all of ou...  ...  [[-7.234983444213867, 0.728289783000946, 0.444...\n",
              "2    The warrants were valued using the Black-Schol...  ...  [[-4.74281644821167, -2.0988667011260986, 0.51...\n",
              "3    In July of 2006, we entered into an operating ...  ...  [[-9.793489456176758, -0.6522069573402405, 0.1...\n",
              "4    Certain regulatory assets do not result from c...  ...  [[-3.82836651802063, 4.249454975128174, -0.112...\n",
              "..                                                 ...  ...                                                ...\n",
              "995  The 2000 volumes reflect the impact of additio...  ...  [[-7.412335395812988, 0.45839157700538635, -0....\n",
              "996  The exercise price per share for each such opt...  ...  [[-1.9446384906768799, -1.06289541721344, -0.9...\n",
              "997  As of June 30, 2006, the outstanding mortgage ...  ...  [[-10.131732940673828, -0.16516311466693878, 1...\n",
              "998  The General Partner and the Commodity Broker p...  ...  [[-5.572422027587891, 2.1878108978271484, -0.9...\n",
              "999  Clients pay for inclusion of their interviews ...  ...  [[1.8370683193206787, 0.5006188154220581, 1.06...\n",
              "\n",
              "[1000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUy9t1NC2MrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = df[df[\"train/test/valid\"]==0].reset_index()\n",
        "valid_df = df[df[\"train/test/valid\"]==1].reset_index()\n",
        "test_df = df[df[\"train/test/valid\"]==2].reset_index()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxziR6ZV2tix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bf958657-f0d1-46b3-da89-c43dbe5f3a61"
      },
      "source": [
        "train_df[\"padded_sent\"][0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-7.23498344,  0.72828978,  0.44459042, ..., -2.13314199,\n",
              "        -1.31469476, -0.80375797],\n",
              "       [-7.89109612,  1.19087827, -1.36637926, ..., -2.85719156,\n",
              "        -2.22213626, -4.2419343 ],\n",
              "       [-7.23125839, -1.00851429,  0.43246418, ..., -3.44821167,\n",
              "        -1.07511806, -0.01868254],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joKmQs1muRM8",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zddxqzms3dYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSrGsbtvt701",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return df.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # cannot return in the form of numpy array\n",
        "        x1 = self.df[\"padded_sent\"][idx]\n",
        "        x2 = self.df[\"sent_avg_emb\"][idx]\n",
        "        y = self.df[\"label\"][idx]\n",
        "        return x1,x2,y"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6zptcqc3cG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_x = train_df[\"padded_sent\"]\n",
        "my_y = train_df[\"label\"]\n",
        "\n",
        "tensor_x = torch.Tensor(my_x) \n",
        "tensor_y = torch.Tensor(my_y)\n",
        "\n",
        "train_ds = TensorDataset(tensor_x,tensor_y) \n",
        "train_dl = DataLoader(train_ds) "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5xFJdGC4Gl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_x = valid_df[\"padded_sent\"]\n",
        "my_y = valid_df[\"label\"]\n",
        "\n",
        "tensor_x = torch.Tensor(my_x) \n",
        "tensor_y = torch.Tensor(my_y)\n",
        "\n",
        "valid_ds = TensorDataset(tensor_x,tensor_y) \n",
        "valid_dl = DataLoader(valid_ds) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBwbq0CJ4GpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_x = test_df[\"padded_sent\"]\n",
        "my_y = test_df[\"label\"]\n",
        "\n",
        "tensor_x = torch.Tensor(my_x) \n",
        "tensor_y = torch.Tensor(my_y)\n",
        "\n",
        "test_ds = TensorDataset(tensor_x,tensor_y) \n",
        "test_dl = DataLoader(test_ds) "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hidGfV2rwrvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_ds = EmbeddingDataset(train_df)\n",
        "# valid_ds = EmbeddingDataset(valid_df)\n",
        "# test_ds = EmbeddingDataset(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f93ba_h-JZE",
        "colab_type": "text"
      },
      "source": [
        "# Model and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YywGEyZo8MgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_optimizer(optimizer, lr):\n",
        "    for i, param_group in enumerate(optimizer.param_groups):\n",
        "        param_group[\"lr\"] = lr"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDbmmSFg8QYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(m, p): torch.save(m.state_dict(), p)\n",
        "    \n",
        "def load_model(m, p): m.load_state_dict(torch.load(p))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K89V2fi7wrxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUModel(torch.nn.Module) :\n",
        "    def __init__(self, embedding_dim, hidden_dim):\n",
        "        super(GRUModel,self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        # self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_pack, ht = self.gru(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA0ng4Tz0KHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epocs(model, optimizer, train_dl, valid_dl, epochs=10):\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        total = 0\n",
        "        best_val_acc = 0\n",
        "        for x, y in train_dl:\n",
        "            x = x.long() #.cuda()\n",
        "            y = y.float() #.cuda()\n",
        "            y_pred = model(x.float())\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            path = \"{0}/models/model_acc_{1:.0f}.pth\".format(PATH,100*val_acc) \n",
        "            save_model(model, path)\n",
        "            print(path)\n",
        "        if i % 5 == 1:\n",
        "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhL3ggw-0uoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_metrics(model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    for x, y in valid_dl:\n",
        "        x = x.long() #.cuda()\n",
        "        y = y.float().unsqueeze(1) #.cuda()\n",
        "        y_hat = model(x.float())\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        y_pred = y_hat > 0\n",
        "        correct += (y_pred.float() == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "    return sum_loss/total, correct/total"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtAM2e5102ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptBC6_aO1EeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GRUModel(embedding_dim=768, hidden_dim=15) #.cuda()\n",
        "\n",
        "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "optimizer = torch.optim.Adam(parameters, lr=0.01)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZpEz2QI1Zlr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "164dfcd6-24d7-402a-e7c2-71b63b24d5e1"
      },
      "source": [
        "train_epocs(model, optimizer, train_dl, valid_dl, epochs=10)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/model_acc_87.pth\n",
            "/content/models/model_acc_87.pth\n",
            "train loss 0.390 val loss 0.389 and val accuracy 0.869\n",
            "/content/models/model_acc_87.pth\n",
            "/content/models/model_acc_87.pth\n",
            "/content/models/model_acc_87.pth\n",
            "/content/models/model_acc_87.pth\n",
            "/content/models/model_acc_87.pth\n",
            "train loss 0.391 val loss 0.389 and val accuracy 0.869\n",
            "/content/models/model_acc_87.pth\n",
            "/content/models/model_acc_87.pth\n",
            "/content/models/model_acc_89.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3moHj7_y53SI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "046e7ba0-75a3-4dd5-f97f-8defd50c0707"
      },
      "source": [
        "train_epocs(model, optimizer, train_dl, valid_dl, epochs=30)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/model_acc_86.pth\n",
            "/content/models/model_acc_92.pth\n",
            "train loss 0.271 val loss 0.295 and val accuracy 0.919\n",
            "/content/models/model_acc_91.pth\n",
            "/content/models/model_acc_89.pth\n",
            "/content/models/model_acc_87.pth\n",
            "/content/models/model_acc_90.pth\n",
            "/content/models/model_acc_90.pth\n",
            "train loss 0.232 val loss 0.215 and val accuracy 0.899\n",
            "/content/models/model_acc_91.pth\n",
            "/content/models/model_acc_91.pth\n",
            "/content/models/model_acc_91.pth\n",
            "/content/models/model_acc_90.pth\n",
            "/content/models/model_acc_91.pth\n",
            "train loss 0.123 val loss 0.312 and val accuracy 0.909\n",
            "/content/models/model_acc_91.pth\n",
            "/content/models/model_acc_89.pth\n",
            "/content/models/model_acc_90.pth\n",
            "/content/models/model_acc_90.pth\n",
            "/content/models/model_acc_90.pth\n",
            "train loss 0.135 val loss 0.302 and val accuracy 0.899\n",
            "/content/models/model_acc_91.pth\n",
            "/content/models/model_acc_89.pth\n",
            "/content/models/model_acc_88.pth\n",
            "/content/models/model_acc_91.pth\n",
            "/content/models/model_acc_92.pth\n",
            "train loss 0.147 val loss 0.252 and val accuracy 0.919\n",
            "/content/models/model_acc_90.pth\n",
            "/content/models/model_acc_92.pth\n",
            "/content/models/model_acc_91.pth\n",
            "/content/models/model_acc_90.pth\n",
            "/content/models/model_acc_93.pth\n",
            "train loss 0.079 val loss 0.257 and val accuracy 0.929\n",
            "/content/models/model_acc_87.pth\n",
            "/content/models/model_acc_90.pth\n",
            "/content/models/model_acc_92.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx_U1W1T_YRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_model(model, \"/content/models/model_acc_93.pth\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAoZP3QD-ngo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dce07ed3-a3ff-4bca-8782-984db20769c8"
      },
      "source": [
        "val_metrics(model, test_dl)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3986194239278297, tensor(0.8835))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}