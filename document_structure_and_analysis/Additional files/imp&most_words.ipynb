{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, remove stop words and stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/usr/local/ifs/gsb/usf_interns/Parser_Project/ParsedDocumentsFolder_new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "realfiles = [fn for fn in files if 'XML' in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4454"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(realfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4455"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_files1 = files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_document_ls = []\n",
    "for fn in sample_files1:\n",
    "    with open(path + fn) as f:\n",
    "        content = f.read()\n",
    "        sample_document_ls.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "ps = PorterStemmer() \n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "def remove_stop_words_and_stem(text):\n",
    "#     text = ' '.join([ps.stem(word) for word in text.split() if word not in (cachedStopWords)])\n",
    "    text = ' '.join([word for word in text.split() if word not in (cachedStopWords)])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to cache stop words first, otherwise will take ages\n",
    "# processed0 = remove_stop_words_and_stem(sample_document_ls[0])\n",
    "# processed1 = remove_stop_words_and_stem(sample_document_ls[1])\n",
    "# processed2 = remove_stop_words_and_stem(sample_document_ls[2])\n",
    "# processed = [remove_stop_words_and_stem(d) for d in sample_document_ls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and the most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words, stem and most frequent words based on TF-IDF and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "def most_important_words_tfidf(processed,n):\n",
    "    X = vectorizer.fit_transform([processed])\n",
    "    indices = np.argsort(vectorizer.idf_)[::-1]\n",
    "    features = vectorizer.get_feature_names()\n",
    "    top_n = n\n",
    "    top_features = [features[i] for i in indices[:top_n]]\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def most_frequent_words(text,n):\n",
    "    counter = Counter(text.split())\n",
    "    return counter.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_length = []\n",
    "ls_imp = []\n",
    "ls_count = []\n",
    "def stats_count(ls,n):\n",
    "    for fn in ls:\n",
    "        with open(path + fn) as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "        length = len(content)\n",
    "        if length == 0:\n",
    "            ls_length.append(0)\n",
    "            ls_imp.append(0)\n",
    "            ls_count.append(0)\n",
    "            continue\n",
    "        content_clean = remove_stop_words_and_stem(content)\n",
    "        important = most_important_words_tfidf(content_clean,n)\n",
    "        count = most_frequent_words(content_clean,n)\n",
    "        ls_length.append(length)\n",
    "        ls_imp.append(important)\n",
    "        ls_count.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_count(realfiles,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.zeros(shape=(4455,4))\n",
    "df = pd.DataFrame(tmp,columns=['name','wordcount','important_words','frequent_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4892"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4892"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4892"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4455"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4454"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(realfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.zeros(shape=(4892,3))\n",
    "df = pd.DataFrame(tmp,columns=['wordcount','important_words','frequent_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['name'] = files\n",
    "df['wordcount'] = ls_length\n",
    "df['important_words'] = ls_imp\n",
    "df['frequent_words'] = ls_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv(\"stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of       Unnamed: 0  wordcount important_words frequent_words\n",
       "8              8          0               0              0\n",
       "9              9          0               0              0\n",
       "21            21          0               0              0\n",
       "32            32          0               0              0\n",
       "34            34          0               0              0\n",
       "45            45          0               0              0\n",
       "56            56          0               0              0\n",
       "62            62          0               0              0\n",
       "66            66          0               0              0\n",
       "71            71          0               0              0\n",
       "76            76          0               0              0\n",
       "79            79          0               0              0\n",
       "82            82          0               0              0\n",
       "84            84          0               0              0\n",
       "97            97          0               0              0\n",
       "159          159          0               0              0\n",
       "164          164          0               0              0\n",
       "179          179          0               0              0\n",
       "184          184          0               0              0\n",
       "187          187          0               0              0\n",
       "202          202          0               0              0\n",
       "206          206          0               0              0\n",
       "216          216          0               0              0\n",
       "220          220          0               0              0\n",
       "221          221          0               0              0\n",
       "228          228          0               0              0\n",
       "233          233          0               0              0\n",
       "236          236          0               0              0\n",
       "254          254          0               0              0\n",
       "260          260          0               0              0\n",
       "...          ...        ...             ...            ...\n",
       "4514        4514          0               0              0\n",
       "4517        4517          0               0              0\n",
       "4595        4595          0               0              0\n",
       "4600        4600          0               0              0\n",
       "4606        4606          0               0              0\n",
       "4626        4626          0               0              0\n",
       "4627        4627          0               0              0\n",
       "4631        4631          0               0              0\n",
       "4656        4656          0               0              0\n",
       "4685        4685          0               0              0\n",
       "4694        4694          0               0              0\n",
       "4715        4715          0               0              0\n",
       "4731        4731          0               0              0\n",
       "4737        4737          0               0              0\n",
       "4752        4752          0               0              0\n",
       "4761        4761          0               0              0\n",
       "4794        4794          0               0              0\n",
       "4798        4798          0               0              0\n",
       "4800        4800          0               0              0\n",
       "4804        4804          0               0              0\n",
       "4821        4821          0               0              0\n",
       "4824        4824          0               0              0\n",
       "4831        4831          0               0              0\n",
       "4832        4832          0               0              0\n",
       "4839        4839          0               0              0\n",
       "4841        4841          0               0              0\n",
       "4850        4850          0               0              0\n",
       "4853        4853          0               0              0\n",
       "4864        4864          0               0              0\n",
       "4871        4871          0               0              0\n",
       "\n",
       "[498 rows x 4 columns]>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[stats[\"wordcount\"] == 0].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateRowsDF = stats[stats.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "df_sfpd = pd.read_csv(sys.argv[1])\n",
    "\n",
    "... delete Incident Categories with nan ...\n",
    "categories = ... create Counter object on column 'Incident Category' ...\n",
    "\n",
    "wordcloud = WordCloud(width=1800,\n",
    "                      height=1400,\n",
    "                      max_words=10000,\n",
    "                      random_state=1,\n",
    "                      relative_scaling=0.25)\n",
    "\n",
    "wordcloud.fit_words(categories)\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wast time'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words_and_stem(\n",
    "    \"it is a waste of time to do this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
